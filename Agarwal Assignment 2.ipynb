{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking Breakdown\n",
    "\n",
    "**70-100%** results/answer correct plus extra achievement at understanding or analysis of results. Clear explanations, evidence of creative or deeper thought will contribute to a higher grade.\n",
    "\n",
    "**60-69%** results/answer correct or nearly correct and well explained.\n",
    "\n",
    "**50-59%** results/answer in right direction but significant errors.\n",
    "\n",
    "**40-49%** some evidence that the student has gained some understanding, but not answered the questions\n",
    "properly.\n",
    "\n",
    "**0-39%** serious error or slack work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics\n",
    "\n",
    "Fill out this notebook, save it, and **submit it electronically as described below.**\n",
    "\n",
    "On a DICE environment, open the terminal, navigate to the location of this notebook, and submit this notebook file using the following command:\n",
    "\n",
    "`submit iaml cw1 05_Assignment_2.ipynb`\n",
    "\n",
    "What actually happens in the background is that your file is placed in a folder available to markers. If you submit a file with the same name into the same location, **it will *overwrite* your previous submission**. You can check the status of your submissions with the `show_submissions` command.\n",
    "\n",
    "**Distance Learners:** To copy your work up to DICE (such that you can use the `submit` command) you can use `scp` or `rsync` (you may need to install these yourself). You can copy files up using `student.ssh.inf.ed.ac.uk`, then ssh in to submit, e.g. (in a unix terminal):\n",
    "```\n",
    "filename=05_Assignment_2.ipynb\n",
    "local_scp_filepath=~/git/iaml2017/${filename}\n",
    "UUN=s0816700\n",
    "server_address=student.ssh.inf.ed.ac.uk\n",
    "scp -r ${local_scp_filepath} ${UUN}@${server_address}:${filename}\n",
    "# rsync -rl ${local_scp_filepath} ${UUN}@${server_address}:${filename}\n",
    "ssh ${UUN}@${server_address}\n",
    "ssh student.login\n",
    "submit iaml cw1 05_Assignment_2.ipynb\n",
    "```\n",
    "\n",
    "**Late submissions:** The policy stated in the School of Informatics MSc Degree Guide is that normally you will not be allowed to submit coursework late. See http://www.inf.ed.ac.uk/teaching/years/msc/courseguide10.html#exam for exceptions to this, e.g. in case of serious medical illness or serious personal problems.\n",
    "\n",
    "**Collaboration:** You may discuss the assignment with your colleagues, provided that the writing that you submit is entirely your own. That is, you should NOT borrow actual text or code from other students. We ask that you provide a list of the people who you've had discussions with (if any).\n",
    "\n",
    "**Resubmission:** If you submit your file again, the previous submission is **overwritten**. We will mark the version that is in the submission folder at the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instructions\n",
    "\n",
    "1. You *MUST* have your environment set up as in the [README](https://github.com/JamesOwers/iaml2017) and you *must activate this environment before running this notebook*:\n",
    "```\n",
    "source activate iaml\n",
    "cd iaml_2017\n",
    "jupyter notebook\n",
    "# Navigate to this file\n",
    "```\n",
    "\n",
    "1. Wherever you are required to produce code you should use code cells, otherwise you should use markdown cells to report results and explain answers.\n",
    "\n",
    "1. The .csv files that you will be using are located at `./datasets` (the `datasets` directory is adjacent to this file).\n",
    "\n",
    "1. **IMPORTANT:** Keep your answers brief and concise. Most written questions can be answered with 2-3 lines of explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Execute the cell below to import all packages you will be using in the rest of the assignemnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "This assignment is based on the automobile pricing dataset. Our goal will be to predict the price of automobiles based on various attributes. This data set consists of three types of entities: \n",
    "\n",
    "1. The specification of an automobile in terms of various characteristics \n",
    "\n",
    "1. Assigned insurance risk rating \n",
    "   * this rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuaries call this process ”symboling”. A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. \n",
    "\n",
    "1. Normalized losses in use as compared to other cars\n",
    "  * the third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year (avg_loss/car/year). \n",
    "\n",
    "\n",
    "To save you time and to make the problem manageable with limited computational resources, we preprocessed the original dataset. We removed any instances that had one or more missing values and randomized the data set. The resulting representation is much more compact and can be used directly to perform our experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Linear Regression [50%]\n",
    "We will begin by studying a simple Linear Regression model. Such a model will consider the relationship between a dependent (response) variable and only one independent (explanatory) variable. When applying machine learning in practice it can be prudent to start out simple in order to get a feeling for the dataset and for any potential difficulties that might warrant a more sophisticated model. In this Section we will consider one independent variable (i.e. feature) `engine-power` against the dependent variable (i.e. target) `price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 --- [1 mark] ==========\n",
    "Load the dataset `train_auto_numeric.csv` into a pandas DataFrame called `auto_numeric`. Display the number of data points and attributes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_numeric = pd.read_csv('datasets/train_auto_numeric.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 --- [1 mark] ==========\n",
    "Display the first 8 instances of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>engine-power</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>mean-effective-pressure</th>\n",
       "      <th>torque</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>8.85</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.52</td>\n",
       "      <td>57.68</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>162.4</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>15.18</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.39</td>\n",
       "      <td>59.59</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158.0</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>15.18</td>\n",
       "      <td>3.94</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3344.79</td>\n",
       "      <td>17710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>158.7</td>\n",
       "      <td>67.7</td>\n",
       "      <td>55.9</td>\n",
       "      <td>13.74</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.50</td>\n",
       "      <td>7.8</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.74</td>\n",
       "      <td>68.97</td>\n",
       "      <td>23875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>8.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.8</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.78</td>\n",
       "      <td>53.48</td>\n",
       "      <td>16430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>194.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>190.9</td>\n",
       "      <td>71.4</td>\n",
       "      <td>58.7</td>\n",
       "      <td>8.67</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.90</td>\n",
       "      <td>22.5</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1330.28</td>\n",
       "      <td>16925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>188.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>26.58</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>377.06</td>\n",
       "      <td>20970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150.0</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>56.1</td>\n",
       "      <td>26.58</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>134000.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>57.37</td>\n",
       "      <td>48.20</td>\n",
       "      <td>21105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normalized-losses  wheel-base  length  width  height  engine-size  bore  \\\n",
       "0              164.0        99.8   176.6   66.2    54.3         8.85  3.19   \n",
       "1              110.0        99.4   162.4   66.4    54.3        15.18  3.19   \n",
       "2              158.0       105.8   192.7   71.4    51.6        15.18  3.94   \n",
       "3              106.0        86.6   158.7   67.7    55.9        13.74  3.13   \n",
       "4              192.0       101.2   176.8   64.8    54.3         8.67  3.50   \n",
       "5              194.0       110.0   190.9   71.4    58.7         8.67  3.78   \n",
       "6              188.0       101.2   176.8   64.8    54.3        26.58  3.31   \n",
       "7              150.0       101.2   176.8   64.8    56.1        26.58  3.03   \n",
       "\n",
       "   stroke  compression-ratio  engine-power  peak-rpm  city-mpg  highway-mpg  \\\n",
       "0    3.40               10.0      102000.0    5500.0      24.0         30.0   \n",
       "1    3.40                8.0      115000.0    5500.0      18.0         22.0   \n",
       "2    2.80                8.5       70000.0    4400.0      28.0         30.0   \n",
       "3    3.50                7.8      140000.0    5600.0      32.0         20.0   \n",
       "4    2.80                8.8      101000.0    5800.0      23.0         29.0   \n",
       "5    3.90               22.5      101000.0    6000.0      47.0         53.0   \n",
       "6    3.19                9.0      121000.0    4250.0      21.0         28.0   \n",
       "7    3.19                8.0      134000.0    4400.0      28.0         37.0   \n",
       "\n",
       "   mean-effective-pressure   torque    price  \n",
       "0                    40.52    57.68  13950.0  \n",
       "1                    47.39    59.59  17450.0  \n",
       "2                     0.85  3344.79  17710.0  \n",
       "3                    44.74    68.97  23875.0  \n",
       "4                    44.78    53.48  16430.0  \n",
       "5                     1.80  1330.28  16925.0  \n",
       "6                     7.19   377.06  20970.0  \n",
       "7                    57.37    48.20  21105.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_numeric.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 --- [1 mark] ==========\n",
    "Display the summary statistics for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>engine-power</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>mean-effective-pressure</th>\n",
       "      <th>torque</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.955975</td>\n",
       "      <td>98.559748</td>\n",
       "      <td>171.698113</td>\n",
       "      <td>65.729560</td>\n",
       "      <td>53.925157</td>\n",
       "      <td>14.056352</td>\n",
       "      <td>3.294528</td>\n",
       "      <td>3.219874</td>\n",
       "      <td>10.446855</td>\n",
       "      <td>98528.301887</td>\n",
       "      <td>5072.012579</td>\n",
       "      <td>27.113208</td>\n",
       "      <td>32.327044</td>\n",
       "      <td>46.180503</td>\n",
       "      <td>200.055031</td>\n",
       "      <td>11684.723270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.434186</td>\n",
       "      <td>5.803361</td>\n",
       "      <td>12.656791</td>\n",
       "      <td>2.292021</td>\n",
       "      <td>2.410446</td>\n",
       "      <td>17.143568</td>\n",
       "      <td>0.296959</td>\n",
       "      <td>0.381833</td>\n",
       "      <td>4.414796</td>\n",
       "      <td>34123.715967</td>\n",
       "      <td>549.988239</td>\n",
       "      <td>7.848229</td>\n",
       "      <td>8.231998</td>\n",
       "      <td>28.780966</td>\n",
       "      <td>513.289289</td>\n",
       "      <td>6744.910579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>141.100000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>5118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>163.400000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>6.960000</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>21.775000</td>\n",
       "      <td>34.140000</td>\n",
       "      <td>7372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>171.700000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>9.030000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>92000.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>55.900000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>145.000000</td>\n",
       "      <td>101.200000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>14.885000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>116000.000000</td>\n",
       "      <td>5450.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>68.495000</td>\n",
       "      <td>119.990000</td>\n",
       "      <td>14719.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>256.000000</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>202.600000</td>\n",
       "      <td>71.700000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>174.160000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>99.850000</td>\n",
       "      <td>3912.870000</td>\n",
       "      <td>42056.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized-losses  wheel-base      length       width      height  \\\n",
       "count         159.000000  159.000000  159.000000  159.000000  159.000000   \n",
       "mean          121.955975   98.559748  171.698113   65.729560   53.925157   \n",
       "std            39.434186    5.803361   12.656791    2.292021    2.410446   \n",
       "min            65.000000   86.600000  141.100000   60.300000   49.400000   \n",
       "25%            93.000000   94.500000  163.400000   64.000000   52.000000   \n",
       "50%           110.000000   97.000000  171.700000   65.400000   54.100000   \n",
       "75%           145.000000  101.200000  177.800000   66.500000   55.600000   \n",
       "max           256.000000  115.600000  202.600000   71.700000   59.800000   \n",
       "\n",
       "       engine-size        bore      stroke  compression-ratio   engine-power  \\\n",
       "count   159.000000  159.000000  159.000000         159.000000     159.000000   \n",
       "mean     14.056352    3.294528    3.219874          10.446855   98528.301887   \n",
       "std      17.143568    0.296959    0.381833           4.414796   34123.715967   \n",
       "min       3.390000    2.540000    2.070000           7.000000   48000.000000   \n",
       "25%       6.960000    3.050000    3.070000           8.600000   69000.000000   \n",
       "50%       9.030000    3.270000    3.270000           9.000000   92000.000000   \n",
       "75%      14.885000    3.580000    3.410000           9.400000  116000.000000   \n",
       "max     174.160000    3.940000    4.170000          23.000000  200000.000000   \n",
       "\n",
       "          peak-rpm    city-mpg  highway-mpg  mean-effective-pressure  \\\n",
       "count   159.000000  159.000000   159.000000               159.000000   \n",
       "mean   5072.012579   27.113208    32.327044                46.180503   \n",
       "std     549.988239    7.848229     8.231998                28.780966   \n",
       "min    4150.000000   15.000000    18.000000                 0.490000   \n",
       "25%    4800.000000   22.000000    26.500000                21.775000   \n",
       "50%    5100.000000   26.000000    32.000000                49.800000   \n",
       "75%    5450.000000   31.000000    37.000000                68.495000   \n",
       "max    6600.000000   49.000000    54.000000                99.850000   \n",
       "\n",
       "            torque         price  \n",
       "count   159.000000    159.000000  \n",
       "mean    200.055031  11684.723270  \n",
       "std     513.289289   6744.910579  \n",
       "min      19.400000   5118.000000  \n",
       "25%      34.140000   7372.000000  \n",
       "50%      55.900000   9233.000000  \n",
       "75%     119.990000  14719.500000  \n",
       "max    3912.870000  42056.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_numeric.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 --- [2 marks] ==========\n",
    "Produce a scatter plot of `price` against `engine-power`. Label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZoVzsDEzs8I52JiZWeH+P3jevDQq7N8HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x146503c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x='price',y='engine-power', data=auto_numeric)\n",
    "plt.title('Car Price vs Engine Power')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Engine Power')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 --- [2 marks] ==========\n",
    "Do you think that engine-power alone is sufficient for predicting the price? Can you make any other observations on the data from the above plot? Please explain your answer in 2-3 sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think that engine-power alone is sufficient for predicting price. Although there is a loose linear pattern visible in the data the single variable alone might not be effective in predicting price accurately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 --- [2 marks] ==========\n",
    "Visualise the distribution of the car prices. Choose a sensible value for the number of bins in the histogram. Again, label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14650240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x='price', data=auto_numeric, bins=10)\n",
    "plt.title('Car Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 --- [2 marks] ==========\n",
    "How could you preprocess the data to improve the performance of linear regression? Don’t do it at this stage, but instead in one sentence explain why you would do what you suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 --- [1 mark] ==========\n",
    "Now we want to build a simple linear regression model. First we need to define our input and target variables. Store the values of the attribute `engine-power` in a vector `X` and the values of our target variable `price` in a vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine_power = np.array(auto_numeric['engine-power'])\n",
    "price = auto_numeric['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.9 --- [1 mark] ==========\n",
    "For technical reasons, we need to convert `X` into a 2D array, otherwise we will receive an error when trying to use it for building models. Perform this transformation and confirm that the shape of the resulting array is (`n`,1) where `n` is the number of instances in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159L, 1L)\n"
     ]
    }
   ],
   "source": [
    "engine_power_mat = engine_power.reshape(engine_power.size, 1)\n",
    "print(engine_power_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.10 --- [1 mark] ==========\n",
    "Now we want to use Hold-out validation to split the dataset into training and testing subsets. Use 80% of the data for training and the remaining 20% for testing. Store your data into matrices `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(engine_power, price, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.11 --- [2 marks] ==========\n",
    "By using Scikit-learn's [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) fit a model to the training data. When initialising the model, set the `normalize` parameter to `True` and use default settings for the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'intercept'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-3151dc41d60e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlinear_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'intercept'"
     ]
    }
   ],
   "source": [
    "linear_reg = LinearRegression(normalize=True).fit(X_train.reshape(-1, 1), y_train)\n",
    "print(linear_reg.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.12 --- [2 marks] ==========\n",
    "By looking into the attributes of your model, write down an equation for predicting the price of a car given the engine-power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.13 --- [3 marks] ==========\n",
    "What happens to the price as one more unit of engine-power is added? By examining the magnitude of the regression coefficient is it possible to tell whether or not engine-power is an important influential variable on price? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.14 --- [2 marks] ==========\n",
    "Produce a scatter plot similar to the one in Question 1.4 but use training data only this time. Add the regression line to the plot and show the predictions on the training set by using a different marker. Label axes appropriately and add a title to the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.15 --- [2 marks] ==========\n",
    "So far we have used Hold-out validation. Can you think of a disadvantage of using this method, especially when dealing with small datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.16 --- [1 mark] ==========\n",
    "Now we want to use k-fold cross-validation to evaluate the performance of the regression model. Famliriase yourself with the sklearn method [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) and make sure you understand the differences between Hold-out and K-fold cross-validation. By using Scikit-learn's [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class construct a 5-fold cross-validation object. Set the `shuffle` parameter to `True` and `random_state` to `0`. Use the object to print the training and validation indices for the `auto_numeric` dataset (hint: see the `split` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.17 --- [3 marks] ==========\n",
    "By making use of the iterator you constructed in the previous question, loop through the 5 folds and display the mean value of the `price` variable for the training instances in each fold. \n",
    "The University of Edinburgh is a charitable body, registered in\n",
    "Scotland, with registration number SC005336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.18 --- [3 marks] ==========\n",
    "Now initialise a new `LinearRegression` model and fit it by making use of the cross-validation iterator, the `X` and `y` arrays defined above and the [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) function. Display the shape of your prediction and confirm it has the same dimensionality as your `y` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.19 --- [2 marks] ==========\n",
    "Report the Coefficient of Determination (R^2), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Correlation Coefficient (CC) from the simple linear regression model you build in Question 1.18. *Hint: RMSE is the square root of the Mean Squared Error (MSE). For CC you might find numpy's [`corrcoef`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html) function useful.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.20 --- [4 marks] ==========\n",
    "What do the above metrics intend to measure? Relate the values of CC, MAE and RMSE to the observations you made in Question 1.5. Explain your answer in 1-2 short paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.21 --- [3 marks] ==========\n",
    "Show a histogram of the residuals of the linear regression model (i.e. true - predicted values). Label axes appropriately and add a title to your plot. Does the distribution of residuals look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.22 --- [2 marks] ==========\n",
    "Load the new dataset `train_auto_base.csv` into a pandas DataFrame `auto_base`. Again by using the `engine-power` attribute as predictor and `price` as target variable build a LinearRegression model on this dataset. Report the R^2, RMSE, MAE and CC metrics for this model by making use of the K-fold CV iterator constructed in Question 1.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.23 --- [2 marks] ==========\n",
    "Show a scatter plot of predicted vs. true prices and another one of predicted price vs. engine-power. Use a single plot with two subplots. Label axes appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.24 --- [3 marks] ==========\n",
    "What is the simplest baseline model for the purposes of regression? Relate your answer to the regression model you have just built as part of this question. Can the predictions of this model be justified given the procedure you followed to train it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.25 --- [2 marks] ==========\n",
    "Why do you think this model performs so poorly? (*Hint: Justify your answer by displaying some statistics about the `auto_base` dataset.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multivariate Linear Regression [50%]\n",
    "In this Section we will fit a Multivariate Linear Regression model (LinearRegression) to the dataset. In contrast to Part 1, we will now train a model with multiple explanatory variables and ascertain how they affect our ability to predict the retail price of a car. One of our foremost concerns will be to determine exactly which attributes to include in the model and which may be left out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 --- [10 marks] ==========\n",
    "Use the original dataset (`auto_numeric`) and a visualisation tool of your choice to examine whether or not any of the other attributes are particularly good at predicting the price. Can you find any? Do any attributes appear useless at predicting the price? Do any attributes exhibit significant correlations? As you answer these questions, list two attributes for each question but do not modify the dataset at this stage. Of the attributes you listed, which ones could you safely remove? Explain in 4-5 sentences. *Hint: you might find seaborn's [`pairplot`](https://seaborn.github.io/generated/seaborn.pairplot.html?highlight=pairplot#seaborn.pairplot) function useful for this question.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 --- [3 marks] ==========\n",
    "We will now make a first attempt at building a Multivariate Linear Regression model using all numeric attributes. Initialise a `LinearRegression` model and predict the output by using 5-fold cross-validation and the `cross_val_predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 --- [2 marks] ==========\n",
    "Display the Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Correlation Coefficient (CC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 --- [2 marks] ==========\n",
    " Comment on each metric display above in comparison to what you have obtained for the Simple Linear Regression model in Question 1.19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 --- [2 marks] ==========\n",
    "Examine the histogram for the `engine-size` attribute. Choose a sensible value for the number of bins in the histogram. Label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 --- [2 marks] ==========\n",
    "Is the distribution expected to cause a problem for regression? Explain your answer in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 --- [3 marks] ==========\n",
    "Transform this attribute using an appropriate simple technique from the lectures. Plot the histogram of the transformed attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 --- [3 marks] ==========\n",
    "Now re-build a Linear Regression model on the transformed dataset and report the R^2, RMSE, MAE and CC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 --- [3 marks] ==========\n",
    "How has the performance of your model changed? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 --- [2 marks] ==========\n",
    "So far we have performed regression with numeric attributes. We will now attempt to integrate nominal (categorical) attributes into our regression model. \n",
    "Load the dataset `train_auto_full.csv` into a pandas DataFrame called `auto_full`. Display the number of samples and attributes in the dataset. Also, display the first 20 instances of the dataset. *Hint: Execute the cell below to change the default for `max_columns` display option in pandas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 --- [3 marks] ==========\n",
    "This dataset contains a mixture of numeric and nominal attributes. Name the variables that you think are categorical. Why can we not use the nominal attributes in their current form for the purposes of regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 --- [5 marks] ==========\n",
    "Now we want to convert the categorical variables by using [One-Hot-Encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder). Familiarise yourself with the class. One limitation with this module is that it can deal only with categorical attributes in integer format (remember that in our example we have attributes in string format). \n",
    "\n",
    "Copy the `auto_full` dataframe into a new dataframe `auto_full_edit` and transform the categorical variables by using [Label Encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Then transform again the categorical variables by using One-Hot-Encoding. Make sure you don't transform the continuous variables. *Hint: make appropriate use of the `categorical_features` parameter in [`OneHotEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).*\n",
    "\n",
    "Store the transformed attributes into a numpy array `X_enc` and display its dimensionality.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 --- [2 marks] ==========\n",
    "By using the transformed data train a multivariate linear regression model and by using 5-fold cross-validation report the R^2, RMSE, MAE and CC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.14 --- [4 marks] ==========\n",
    "How does this more complex model perform with respect to your best performing model from either question 2.3 or 2.8? List one advantage and one disadvantage of using the more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.15 --- [4 marks] ==========\n",
    "Finally, experiment with tree-based regressors (e.g. [`DecisionTreeRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html), [`RandomForestRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)) and report 5-fold cross-validation scores for R^2, RMSE, MAE and CC. Has your performance improved? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
